{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cardiovascular-curve",
   "metadata": {},
   "source": [
    "# Assignment 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-substance",
   "metadata": {},
   "source": [
    "## Assignment 10.1.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "waiting-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def text_cleaning(text):\n",
    "    \"\"\"\n",
    "    # Define function to perform below text cleaning\n",
    "    # Make text lowercase\n",
    "    # Remove text in square brackets\n",
    "    # Remove links\n",
    "    # Remove special characters\n",
    "    # Remove words containing numbers\n",
    "    # Remove punctuation\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\b\\w{1,2}\\b', '', text) # removes words with 2 or less charectors.\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(\"\\\\W\",\" \",text) # remove special chars\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def tokenize(sentence):\n",
    "    \"\"\"\n",
    "    tokanizes a corpus\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "#     sentence = sentence.lower()\n",
    "#     sentence = re.sub(' +',' ',sentence)\n",
    "    tokens = re.findall(\"[\\w']+\", text_cleaning(sentence))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "modern-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize(\"Founded founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed liquid-fuel launch vehicle to orbit the Earth.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "brazilian-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-career",
   "metadata": {},
   "source": [
    "## Assignment 10.1.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "attempted-macintosh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fewer-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(tokens, n):\n",
    "    \"\"\"\n",
    "    Creates n grams from a token of words\n",
    "    \"\"\"\n",
    "    ngrams = []\n",
    "    # Create ngrams\n",
    "#     for i in range(len(tokens) - n+1):\n",
    "#         ngrams.append(tokens[i:i+n])\n",
    "    mgram = [ngrams.append(tokens[i:i+n]) for i in range(len(tokens) - n+1)]\n",
    "    ngrams = [\" \".join(ngram) for ngram in ngrams]\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "rational-denial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['founded founded spacex mission enable',\n",
       " 'founded spacex mission enable humans',\n",
       " 'spacex mission enable humans become',\n",
       " 'mission enable humans become spacefaring',\n",
       " 'enable humans become spacefaring civilization',\n",
       " 'humans become spacefaring civilization and',\n",
       " 'become spacefaring civilization and multi',\n",
       " 'spacefaring civilization and multi planet',\n",
       " 'civilization and multi planet species',\n",
       " 'and multi planet species building',\n",
       " 'multi planet species building self',\n",
       " 'planet species building self sustaining',\n",
       " 'species building self sustaining city',\n",
       " 'building self sustaining city mars',\n",
       " 'self sustaining city mars spacex',\n",
       " 'sustaining city mars spacex falcon',\n",
       " 'city mars spacex falcon became',\n",
       " 'mars spacex falcon became the',\n",
       " 'spacex falcon became the first',\n",
       " 'falcon became the first privately',\n",
       " 'became the first privately developed',\n",
       " 'the first privately developed liquid',\n",
       " 'first privately developed liquid fuel',\n",
       " 'privately developed liquid fuel launch',\n",
       " 'developed liquid fuel launch vehicle',\n",
       " 'liquid fuel launch vehicle orbit',\n",
       " 'fuel launch vehicle orbit the',\n",
       " 'launch vehicle orbit the earth']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(tokens, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-breeding",
   "metadata": {},
   "source": [
    "## Assignment 10.1.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "conditional-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot_encode(tokens, num_words):\n",
    "#     token_index = {}\n",
    "#     results = ''\n",
    "\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    print(integer_encoded)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    print(onehot_encoded)\n",
    "    # invert first example\n",
    "    inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "    print(inverted)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-immune",
   "metadata": {},
   "source": [
    "## Assignment 10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-execution",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
